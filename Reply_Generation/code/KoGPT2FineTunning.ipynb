{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19781cdf-db46-4295-8202-af839fbbc58a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-03 18:20:26.428432: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-03 18:20:26.457533: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-03 18:20:26.457572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-03 18:20:26.458424: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-03 18:20:26.463603: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-03 18:20:27.146548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import urllib.request\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import torch.nn as nn\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel,TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40815684-b0fd-4f96-81da-db65ea696601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_df_naver_kin.csv')\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2a9e94-eaf8-4028-9484-f01e2730e20a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "Q_TKN = \"<usr>\"\n",
    "A_TKN = \"<sys>\"\n",
    "BOS = '</s>'\n",
    "EOS = '</s>'\n",
    "MASK = '<unused0>'\n",
    "SENT = '<unused1>'\n",
    "PAD = '<pad>'\n",
    "max_len = 800\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/kogpt2-base-v2',\n",
    "                                                           bos_token = BOS, eos_token =EOS,\n",
    "                                                           unk_token ='<unk',pad_token = PAD,\n",
    "                                                           mask_token = MASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2ecd4c-624b-4fee-814b-f27b52374912",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>que_token_len</th>\n",
       "      <th>an_token_len</th>\n",
       "      <th>sum_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>102.684898</td>\n",
       "      <td>144.668163</td>\n",
       "      <td>247.353061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>641.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>908.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        que_token_len  an_token_len     sum_len\n",
       "mean       102.684898    144.668163  247.353061\n",
       "median      81.000000    136.000000  230.000000\n",
       "max        641.000000    630.000000  908.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['que_token_len'] = data['Q'].apply(lambda x:len(tokenizer.tokenize(x)))\n",
    "data['an_token_len'] = data.iloc[:,1].apply(lambda x:len(tokenizer.tokenize(x)))\n",
    "data['sum_len'] = data['que_token_len']+ data['an_token_len']\n",
    "\n",
    "data.agg({'que_token_len':['mean','median','max'],'an_token_len':['mean','median','max'],'sum_len':['mean','median','max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1abeb62d-3590-4877-b9a8-82b08f6e06ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>que_token_len</th>\n",
       "      <th>an_token_len</th>\n",
       "      <th>sum_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저는 예비 중1입니다. 일단 우울증인 것 같기는 한데 아직 잘 모르겠어서요. 우울증...</td>\n",
       "      <td>우울증 테스트는 신뢰할만하지 않습니다. 중요한 것은 본인의 현재 우울한 상태입니다....</td>\n",
       "      <td>106</td>\n",
       "      <td>116</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>청주 30대 후반/여 우울증우울증 극복 어떻하죠 남들하고 비교하다보니 자존감이 너무...</td>\n",
       "      <td>우울증 극복 방법은 다양하게 있지만, 우선적으로 우울에 대한 감정과 우울증에 대한 ...</td>\n",
       "      <td>31</td>\n",
       "      <td>198</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>잠실 10대 초반/여 우울증아이가 10살인데 우울증 증상을 보입니다.처음에는 의심되...</td>\n",
       "      <td>우울증을 겪는 아이들을 치료하기 위해서는 안전하고 효과적인 방법을 사용해야 합니다....</td>\n",
       "      <td>64</td>\n",
       "      <td>111</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40대 중반/여청소년 우울증 상담 질문드리고 싶어요... 아이가 지금 청소년 우울증...</td>\n",
       "      <td>청소년 우울증에 대한 해결책으로는 다음과 같은 접근 방법을 권장드립니다. 첫째로, ...</td>\n",
       "      <td>105</td>\n",
       "      <td>261</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>초딩 졸업을 앞두고 있는 학생인데요가정사도 안 좋아지고 정말 사랑하는 남친이랑 싸우...</td>\n",
       "      <td>우선, 언급한 내용으로 보아 우울증에 의한 것일 수도 있고 급작스런 스트레스 상황으...</td>\n",
       "      <td>165</td>\n",
       "      <td>90</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>현재 중3 여학생입니다 요즘 울음을 많이 터트리는데 어제도 자신있던 과목에서 실수하...</td>\n",
       "      <td>우울증은 감정이 격해지는 것과 다른 부분들은 다 같이 행동한다는 점을 강조하셨습니다...</td>\n",
       "      <td>221</td>\n",
       "      <td>197</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>우울증 예방법 좀 알려주세요..그리고 그 예방법이 왜 예방법인지도 …</td>\n",
       "      <td>우울증의 원인은 생활에서 해로운 요소들입니다. 이러한 요소들을 제거하면서 줄일 수,...</td>\n",
       "      <td>21</td>\n",
       "      <td>193</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>나 자신이 우울증인 것 같다는 생각이 들면우울증인걸까요..?평소에 조울증처럼 기분도...</td>\n",
       "      <td>우선, 자기 자신이 스스로 판단하는 것은 하지만 그러므로, 현재 알고 있는 감정이 ...</td>\n",
       "      <td>203</td>\n",
       "      <td>90</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>어두워 지고 방에 혼자 있으면자꾸 우울해지곤 합니다 요새는 불안하고 심장이 잘못한 ...</td>\n",
       "      <td>우선, 저는 정신과 / 임상심리전문가 해말근이라고 알려진 질문자님의 마음의 감기 다...</td>\n",
       "      <td>57</td>\n",
       "      <td>162</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>입사하고 약2년 정도 우울증 약 복용중입니다회사 스트레스/ 개인적인 일 등 여러가지...</td>\n",
       "      <td>제가 이해합니다. 퇴사는 개인의 권리이며, 이에 대한 얘기를 하지 않아도 된다는 점...</td>\n",
       "      <td>110</td>\n",
       "      <td>55</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2447 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Q  \\\n",
       "0     저는 예비 중1입니다. 일단 우울증인 것 같기는 한데 아직 잘 모르겠어서요. 우울증...   \n",
       "1     청주 30대 후반/여 우울증우울증 극복 어떻하죠 남들하고 비교하다보니 자존감이 너무...   \n",
       "2     잠실 10대 초반/여 우울증아이가 10살인데 우울증 증상을 보입니다.처음에는 의심되...   \n",
       "3     40대 중반/여청소년 우울증 상담 질문드리고 싶어요... 아이가 지금 청소년 우울증...   \n",
       "4     초딩 졸업을 앞두고 있는 학생인데요가정사도 안 좋아지고 정말 사랑하는 남친이랑 싸우...   \n",
       "...                                                 ...   \n",
       "2445  현재 중3 여학생입니다 요즘 울음을 많이 터트리는데 어제도 자신있던 과목에서 실수하...   \n",
       "2446             우울증 예방법 좀 알려주세요..그리고 그 예방법이 왜 예방법인지도 …   \n",
       "2447  나 자신이 우울증인 것 같다는 생각이 들면우울증인걸까요..?평소에 조울증처럼 기분도...   \n",
       "2448  어두워 지고 방에 혼자 있으면자꾸 우울해지곤 합니다 요새는 불안하고 심장이 잘못한 ...   \n",
       "2449  입사하고 약2년 정도 우울증 약 복용중입니다회사 스트레스/ 개인적인 일 등 여러가지...   \n",
       "\n",
       "                                                      A  que_token_len  \\\n",
       "0     우울증 테스트는 신뢰할만하지 않습니다. 중요한 것은 본인의 현재 우울한 상태입니다....            106   \n",
       "1     우울증 극복 방법은 다양하게 있지만, 우선적으로 우울에 대한 감정과 우울증에 대한 ...             31   \n",
       "2     우울증을 겪는 아이들을 치료하기 위해서는 안전하고 효과적인 방법을 사용해야 합니다....             64   \n",
       "3     청소년 우울증에 대한 해결책으로는 다음과 같은 접근 방법을 권장드립니다. 첫째로, ...            105   \n",
       "4     우선, 언급한 내용으로 보아 우울증에 의한 것일 수도 있고 급작스런 스트레스 상황으...            165   \n",
       "...                                                 ...            ...   \n",
       "2445  우울증은 감정이 격해지는 것과 다른 부분들은 다 같이 행동한다는 점을 강조하셨습니다...            221   \n",
       "2446  우울증의 원인은 생활에서 해로운 요소들입니다. 이러한 요소들을 제거하면서 줄일 수,...             21   \n",
       "2447  우선, 자기 자신이 스스로 판단하는 것은 하지만 그러므로, 현재 알고 있는 감정이 ...            203   \n",
       "2448  우선, 저는 정신과 / 임상심리전문가 해말근이라고 알려진 질문자님의 마음의 감기 다...             57   \n",
       "2449  제가 이해합니다. 퇴사는 개인의 권리이며, 이에 대한 얘기를 하지 않아도 된다는 점...            110   \n",
       "\n",
       "      an_token_len  sum_len  \n",
       "0              116      222  \n",
       "1              198      229  \n",
       "2              111      175  \n",
       "3              261      366  \n",
       "4               90      255  \n",
       "...            ...      ...  \n",
       "2445           197      418  \n",
       "2446           193      214  \n",
       "2447            90      293  \n",
       "2448           162      219  \n",
       "2449            55      165  \n",
       "\n",
       "[2447 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_800 = data[data['sum_len']>800]\n",
    "data = data.drop(index = data_800.index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1220ac6a-cf89-4607-9ede-07e565400951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[['Q','A']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "482b9691-e66a-4988-9c55-00df68bfc78b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(data, test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6fabe08-e045-45e2-9d9f-bef521acae66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self,chats, max_len = max_len):\n",
    "        self._data = chats\n",
    "        self.max_len = max_len\n",
    "        self.q_token = Q_TKN\n",
    "        self.a_token = A_TKN\n",
    "        self.sent_token = SENT\n",
    "        self.eos = EOS\n",
    "        self.mask = MASK\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        turn = self._data.iloc[idx]\n",
    "        q = turn['Q']\n",
    "\n",
    "        a = turn['A']\n",
    "\n",
    "        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n",
    "        q_len = len(q_toked)\n",
    "\n",
    "        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
    "        a_len = len(a_toked)\n",
    "\n",
    "        # 질문의 길이와 답변의 길이의 합이 max_len이어야함.\n",
    "\n",
    "        # 1. 질문만으로 max_len을 넘을 때\n",
    "        if q_len > self.max_len:\n",
    "            a_len = self.max_len - q_len\n",
    "            if a_len <= 0:\n",
    "                q_toked = q_toked[-(int(self.max_len/2)):]\n",
    "\n",
    "                q_len = len(q_toked)\n",
    "                a_len = self.max_len - q_len\n",
    "\n",
    "            a_toked = a_toked[:a_len]\n",
    "            a_len = len(a_toked)\n",
    "\n",
    "            a_toked = a_toked[:a_len]\n",
    "            a_len = len(a_toked)\n",
    "\n",
    "\n",
    "        # 2. 질문의 길이는 max_len을 안넘지만\n",
    "        # 질문의 길이와 답변의 길이가 최대 길이보다 클 때\n",
    "        if q_len + a_len > self.max_len:\n",
    "            a_len = self.max_len - q_len\n",
    "\n",
    "            if a_len <= 0:\n",
    "\n",
    "                q_toked = q_toked[-(int(self.max_len /2)):]\n",
    "\n",
    "                q_len = len(q_toked)\n",
    "                a_len = self.max_len - q_len\n",
    "\n",
    "            a_toked = a_toked[:a_len] # a_toked는 A_TKN과 answer 그리고 EOS가 포함되어 있음.\n",
    "            a_len = len(a_toked)\n",
    "\n",
    "        labels = [self.mask,] * q_len + a_toked[1:] # answer부터 EOS까지 넣기 위함.\n",
    "        ## 형태\n",
    "        ## [mask,mask,mask...., answer_id1, answer_id2, .... , EOS]\n",
    "\n",
    "\n",
    "\n",
    "        # 질문 길이 + 답변길이가 max_len을 넘지 않을 때\n",
    "        # 질문길이 0 + 답변길이 1 + 나머지 0\n",
    "        mask = [0]*q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
    "\n",
    "        ## 위의 조건문들에 의해 질문 길이 + 답변길이의 합이 max_len을 넘지 않는 것들밖에 없음\n",
    "        ## answer을 제외한 다른 것들을 0으로 패딩하는 과정인가봄.\n",
    "\n",
    "        # 답변 labels를 index로 만든다.\n",
    "        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
    "\n",
    "        while len(labels_ids) < self.max_len:\n",
    "            labels_ids += [self.tokenizer.pad_token_id]\n",
    "\n",
    "        # 질문 + 답변을 index로 만든다.\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked+ a_toked)\n",
    "\n",
    "        # 최대 길이만큼 padding\n",
    "\n",
    "        while len(token_ids) < self.max_len:\n",
    "            token_ids += [self.tokenizer.pad_token_id]   # tokenizer.pad_token_id는 앞에 입력했던 paddig token인 PAD\n",
    "\n",
    "        # 질문 + 답변, 마스크, 답변\n",
    "\n",
    "        return (token_ids, np.array(mask), labels_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e014c6f8-2770-4440-8781-a77dfbc978e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.init()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# def collate_batch(batch):\n",
    "#     inputs, masks, labels = zip(*batch)\n",
    "\n",
    "#     # Convert masks to tensors\n",
    "#     masks = torch.stack([torch.tensor(mask) for mask in masks]).to('cuda:0')\n",
    "\n",
    "#     # Convert labels to tensors\n",
    "#     labels = torch.stack([torch.tensor(label) for label in labels]).to('cuda:0')\n",
    "\n",
    "#     return inputs, masks, labels\n",
    "def collate_batch(batch):\n",
    "    data = np.array([item[0] for item in batch])\n",
    "    mask = np.array([item[1] for item in batch])\n",
    "    label = np.array([item[2] for item in batch])\n",
    "\n",
    "    return torch.LongTensor(data).to(device), torch.LongTensor(mask).to(device), torch.LongTensor(label).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "825614eb-898d-4a10-b182-9fa4d1d14289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = ChatbotDataset(train_dataset, max_len=800)\n",
    "train_dataloader = DataLoader(train_set, batch_size=4, num_workers=0, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a78f06ab-49f7-43d7-918a-ca1af14d4256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d07e4c98-0a07-4616-a49c-9d41baa2b358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "print(device)\n",
    "\n",
    "learning_rate = 3e-5\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epoch = 10\n",
    "Sneg = -1e18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02fa119-ecb3-4ace-aa7f-a31a28d422b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  50%|███████████████████████████████████▌                                   | 5/10 [12:07<12:07, 145.49s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epoch),desc = 'Processing'):\n",
    "    for batch_idx, samples in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids, mask ,label = samples\n",
    "        out = model(token_ids)\n",
    "        out_logits = out.logits  # 인풋 요소의 로짓이 들어있는 텐서가 반환됨.\n",
    "\n",
    "        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats = out_logits.shape[2], dim = 2)\n",
    "\n",
    "        mask_out = torch.where(mask_3d == 1, out_logits, Sneg * torch.ones_like(out_logits))\n",
    "\n",
    "        loss = criterion(mask_out.transpose(2,1),label)\n",
    "\n",
    "        avg_loss = loss.sum() / mask.sum()\n",
    "        avg_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(), \"chatbot_naver_kin_10_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1528537-0d0b-4d31-bd44-4294f7aa1b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "model_state_dict = torch.load(\"chatbot_naver_kin_weight\", map_location='cpu')\n",
    "model2.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9d01307-70b6-4023-acb2-404f2b96ab1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user >  너무 힘들고 피곤해 울고 싶어\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot > 힘들고 지쳐 느껴진다면, 상담을 받아보는 것이 좋습니다. 전문가들은 우울증에 대한 전문적인 지식과 경험을 가지고 있어서 도움이 될 수 있습니다. 그러나 너무 힘들고 지쳐 느껴진다면, 전문 상담을 받아보는 것을 추천드립니다. 상담을 통해 우울증에 대한 이해와 도움을 얻을 수 있고, 전문가들은 당신의 상황을 평가하고 적절한 치료 방법을 제시해줄 수 있을 것입니다. 또한, 일상적인 생활 습관을 개선하는 것도 중요합니다. 충분한 수면을 취하고, 균형 잡힌 식단을 유지하며, 규칙적인 운동을 실천하는 것이 도움이 될 수 있습니다. 사랑하는 사람들과 시간을 보내거나 취미를 가진 것도 우울증을 극복하는 데 도움이 될 수 있습니다. 우울증은 치료 가능한 상태이며, 전문가의 도움을 받아 치료받을 수 있습니다. 따라서, 전문가의 도움을 받아고 싶다면, 전문 상담을 받아보고 전문가의 조언을 받는 것이 좋습니다. 그들은 당신의 상황을 이해하고 적절한 치료 방법을 제시해줄 수 있을 것입니다. 하지만, 힘들고 지쳐 느껴진다면, 전문 상담을 받아보는 것을 권장드립니다. 상담을 통해 우울증을 극복하고, 긍정적인 변화를 이끌어낼 수 있을 것입니다.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m         q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser > \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1179\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1180\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    while 1:\n",
    "        q = input(\"user > \").strip()\n",
    "        if q == \"quit\":\n",
    "            break\n",
    "        a = \"\"\n",
    "        while 1:\n",
    "            #input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + sent + A_TKN + a)).unsqueeze(dim=0)\n",
    "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + A_TKN + a)).unsqueeze(dim=0)\n",
    "            pred = model2(input_ids)\n",
    "            pred = pred.logits\n",
    "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n",
    "            if gen == EOS:\n",
    "                break\n",
    "            a += gen.replace(\"▁\", \" \")\n",
    "        print(\"Chatbot > {}\".format(a.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ccba48b-c56d-44e1-89f6-f34ebda451fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_naver_5_finetuned = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "model_state_dict = torch.load(\"chatbot_naver_kin_5_weight\", map_location='cpu')\n",
    "model_naver_5_finetuned.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabe381c-e0f2-4388-80f4-1d5cd896d09c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/HyeoGyu/kogpt_naver_5_finetuned/commit/9c385509a447ed37673e1e4f182346a25df49905', commit_message='Upload tokenizer', commit_description='', oid='9c385509a447ed37673e1e4f182346a25df49905', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPO_NAME = 'kogpt_naver_5_finetuned'\n",
    "AUTH_TOKEN = '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'\n",
    "## Upload to Huggingface Hub\n",
    "model_naver_5_finetuned.push_to_hub(\n",
    "    REPO_NAME,\n",
    "    use_temp_dir=True,\n",
    "    use_auth_token=AUTH_TOKEN\n",
    ")\n",
    "tokenizer.push_to_hub(\n",
    "    REPO_NAME,\n",
    "    use_temp_dir=True,\n",
    "    use_auth_token=AUTH_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db59285f-c647-4525-b767-84bbdab27908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbefb8a4d9141fa97800c116fbdea7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/268 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e239b7e7614b048372db0d7f9b3cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3135b22e3a4ebdb30cc0787d67249e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeabd18f702e4c2a9cc5ef1c4f0ce021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff167ad1930443f8196b3f7154b332e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e001d060c57d44dd84bae7e543c39d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HyeoGyu/kogpt_naver_5_finetuned\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"HyeoGyu/kogpt_naver_5_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811ce9e6-3aa3-4f02-992f-e46db8d4e41e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user >  오늘 일이 너무 많아서 힘들었어\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot > 우울증에 대한 해결책으로는 정신과 상담을 받는 것이 좋습니다. 정신과 전문의들은 우울증에 대한 전문적인 지식과 경험을 가지고 있어서 적절한 치료 방법을 제시해줄 수 있습니다. 그러나 정신과 상담은 전문가가 직접 진단을 내리는 것이 아니라 상담을 통해 우울증의 원인을 파악하고, 그에 맞는 개별적인 치료 방법을 제시해줄 수 있습니다. 그러나 우울증은 심리적인 문제이기 때문에 전문가의 도움이 필요합니다. 따라서 일단은 상담을 통해 심리적인 원인을 파악하고, 그 해결책을 찾는 것이 중요합니다. 또한 정신과 전문의나 상담사와의 상담을 통해 심리적인 지원을 받고, 전문가의 도움을 받아, 우울증을 극복할 수 있는 방법을 찾을 수 있을 것입니다. 하지만 우울증은 심리적인 문제이기 때문에, 전문가의 도움을 받는 것이 중요합니다. 따라서 일단은 정신과 전문의나 상담사와의 상담을 통해 심리적인 문제를 해결하고, 그걸 통해 긍정적인 변화를 찾을 수 있을 것입니다. 그러나 정신과 전문의나 상담사와의 상담을 통해 그 원인을 파악하고, 그에 맞는 개별적인 치료 방법을 찾을 수 있을 것입니다. 따라서 일단은 정신과 전문의나 상담사와의 상담을 통해 일단은 도움을 받을 수 있을 것입니다. 그러나 우울증은 심리적인 문제이기 때문에, 전문가의 도움 받는 것이 중요합니다. 따라서 일단은 정신과 전문의나 상담사와의 상담을 통해 심리적인 지원을 받고, 긍정적인 변화를 찾을 수 있을 것입니다. 그러나 우울증은 심리적인 문제이므로, 전문가의 도움 받는 것이 중요합니다. 따라서 일단은 정신과 전문의나 상담사와의 상담을 통해 심리적인 지원을 받고, 긍정적인 변화를 찾을 수 있을 것입니다. 그러나 우울증은 심리적인 문제이므로, 전문가의 도움 받는 것이 중요합니다. 따라서 일단은 정신과 전문의나 상담사와의 상담을 통해 심리적인 지원을 받고, 긍정적인 변화를 찾을 수 있을 것입니다. 그러나 우울증은 심리적인 문제이므로, 전문가의 도움을 받는 것이 중요합니다. 따라서 일단은 정신과 전문의나 상담사와의 상담을 통해 심리적인 지원을 받고, 긍정적인 변화를 찾을 수 있을 것입니다. 그러나 우울증은 심리적인 문제이므로, 전문가의 도움을 받는 것이 중요합니다. 따라서 일단은 일단은 정신과 전문의나 상담사와의 도움을 받고, 일단은 일단은 일단은 일단은 일상을 되찾아갈 수 있을 것입니다. 그러나 우울증은 심리적인 문제이므로, 일단은 일단은 일상을 되찾아갈 수 있을 것입니다. 그러나 일단은 일상을 되찾아갈 수 있을 것이며, 이는 긍정적인 변화를 찾을 수 있을 것입니다. 그러나 우울증은 혼자서 해결하기 어려운 질병이므로, 전문가의 도움 받는 것이 중요합니다. 따라서 우울증이라고 생각한다면, 전문가의 도움을 받는 것이 중요합니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user >  </s>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot > 우울증에 대한 해결책으로는 심리 상담을 받는 것이 좋습니다. 심리 상담은 전문가와의 대화를 통해 우울증의 원인을 파악하고, 적절한 치료 방법을 배우는 과정입니다. 또한, 심리 상담은 개인의 심리적인 어려움을 이해하고 도움을 주는 중요한 도구입니다. 따라서 우선적으로, 심리 상담을 통해 우울증의 원인을 파악하고, 그에 맞는 치료 방법을 배울 수 있습니다. 또한, 심리 상담은 개인의 심리적인 어려움을 이해하고 도움을 줄 수 있는 중요한 도구입니다. 따라서, 먼저, 심리 상담을 받아보는 것을 추천드립니다. 상담은 우울증을 극복하기 위한 첫 단계 매우 유용한 도구입니다. 심리 상담은 우울증의 원인을 파악하고, 적절한 치료 방법을 배우는 과정이며, 또한, 심리 상담은 개인의 심리적인 어려움을 이해하고 지원하는 중요한 도구입니다. 따라서, 심리 상담을 받아보는 것을 추천드립니다.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m         q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser > \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1179\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1180\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    while 1:\n",
    "        q = input(\"user > \").strip()\n",
    "        if q == \"quit\":\n",
    "            break\n",
    "        a = \"\"\n",
    "        while 1:\n",
    "            #input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + sent + A_TKN + a)).unsqueeze(dim=0)\n",
    "            input_ids = torch.LongTensor(tokenizer.encode(Q_TKN + q + SENT + A_TKN + a)).unsqueeze(dim=0)\n",
    "            pred = model(input_ids)\n",
    "            pred = pred.logits\n",
    "            gen = tokenizer.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n",
    "            if gen == EOS:\n",
    "                break\n",
    "            a += gen.replace(\"▁\", \" \")\n",
    "        print(\"Chatbot > {}\".format(a.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50c4e0-13ae-444c-b12c-fdbfe1b86c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
