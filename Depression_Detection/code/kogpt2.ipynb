{"cells":[{"cell_type":"markdown","metadata":{"id":"HQriQzS6xJ8W"},"source":["- https://github.com/ukairia777/tensorflow-nlp-tutorial/blob/main/22.%20Fine-tuning%20GPT-2%20(Cls%2C%20Chatbot%2C%20NLI)/22-4.%20kogpt2_nsmc_tpu.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8938,"status":"ok","timestamp":1706507581103,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"h7TPztkdcdLO","outputId":"2e739001-206f-4d05-a625-0bd58d9c659d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}],"source":["pip install transformers"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16qAuRh9oMLf","executionInfo":{"status":"ok","timestamp":1706765389772,"user_tz":-540,"elapsed":20298,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"c88dbc5d-2cdf-4d72-e4a0-8645ca3f49b0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":7140,"status":"ok","timestamp":1706765396907,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"nY4HfcDXikCI","outputId":"06eb66d0-2e24-4dc4-da46-19799658a927"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'4.35.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["import transformers\n","transformers.__version__"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7196,"status":"ok","timestamp":1706765404101,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"HPC7cPCrnF0q"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import urllib.request\n","import os\n","from tqdm import tqdm\n","import tensorflow as tf\n","from transformers import AutoTokenizer, TFGPT2Model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"markdown","source":["## 데이터 불러오기"],"metadata":{"id":"MGRhcJaMqQ47"}},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":685,"status":"ok","timestamp":1706766510732,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"opGrZfOseqRi"},"outputs":[],"source":["train_data = pd.read_csv('/content/drive/MyDrive/CUAI 컨퍼런스/data/merged_df(감정 분류).csv')[['content', 'label']]\n","test_data = pd.read_csv('/content/drive/MyDrive/CUAI 컨퍼런스/data/test_data.csv')\n","test_data['content'] = test_data['title'] + ' ' + test_data['content']"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1706766510732,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"aiF5GOyxelOY","outputId":"8761b126-59b6-4a8e-e1c6-5f481d917e70"},"outputs":[{"output_type":"stream","name":"stdout","text":["훈련용 리뷰 개수 : 45999\n"]}],"source":["print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 데이터 개수 출력"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706766511053,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"ZfefWt-2eoDS","outputId":"9532fb36-4cad-4a53-83b1-8b2c13bb3ed7"},"outputs":[{"output_type":"stream","name":"stdout","text":["테스트용 리뷰 개수 : 390\n"]}],"source":["print('테스트용 리뷰 개수 :',len(test_data)) # 테스트용 데이터 개수 출력"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1706766512202,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"vWSh9Lc-esFC","outputId":"686d9336-7b54-4c4f-c36a-ebb0c39b15a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}],"source":["train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n","train_data = train_data.reset_index(drop=True)\n","print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706766512542,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"tAgd9TbRetIa","outputId":"7a1a4312-8fd2-4923-abbf-c6b810844211"},"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}],"source":["test_data = test_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n","test_data = test_data.reset_index(drop=True)\n","print(test_data.isnull().values.any()) # Null 값이 존재하는지 확인"]},{"cell_type":"markdown","source":["## 전처리"],"metadata":{"id":"doLgReJfqte2"}},{"cell_type":"markdown","source":["#### 불용어 처리"],"metadata":{"id":"5WPtQxL86FEL"}},{"cell_type":"code","source":["# # 문자열 아닌 데이터 모두 제거\n","train_data['content'] = [content for content in train_data['content'] if type(content) is str]\n","test_data['content'] = [content for content in test_data['content'] if type(content) is str]"],"metadata":{"id":"JYwRcKAeoo6X","executionInfo":{"status":"ok","timestamp":1706766515196,"user_tz":-540,"elapsed":470,"user":{"displayName":"좌대현","userId":"14506643217253030071"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']"],"metadata":{"id":"Ng9ZXCVNrioz","executionInfo":{"status":"ok","timestamp":1706766516364,"user_tz":-540,"elapsed":275,"user":{"displayName":"좌대현","userId":"14506643217253030071"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','것','이다','게','에서','거','로','수','에게','요']"],"metadata":{"id":"1cTEL0xRSlNG","executionInfo":{"status":"ok","timestamp":1706766516792,"user_tz":-540,"elapsed":2,"user":{"displayName":"좌대현","userId":"14506643217253030071"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["pip install konlpy"],"metadata":{"id":"YA_pF311wIF2","executionInfo":{"status":"ok","timestamp":1706766524139,"user_tz":-540,"elapsed":0,"user":{"displayName":"좌대현","userId":"14506643217253030071"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","from tqdm import tqdm\n","\n","# KoNLPy의 Okt 형태소 분석기를 사용하여 불용어 제거\n","okt = Okt()\n","\n","def remove_stopwords(text):\n","    words = okt.pos(text, stem=False)  # 형태소 분석, (stem=True -> 기본형?으로 나옴)\n","    filtered_words = [word for word, pos in words if word not in stopwords]  # 불용어 제거\n","    return ' '.join(filtered_words)\n","\n","\n","# 'content' 열에 있는 각 텍스트에 대해 불용어 제거 수행\n","tqdm.pandas()\n","train_data['content'] = train_data['content'].progress_apply(remove_stopwords)\n","test_data['content'] = test_data['content'].progress_apply(remove_stopwords)"],"metadata":{"id":"avbK8lrtyiel","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706766789553,"user_tz":-540,"elapsed":265422,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"e9b8e2df-4dd1-4f2c-ce46-0560746364c6"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 45999/45999 [04:20<00:00, 176.35it/s]\n","100%|██████████| 390/390 [00:04<00:00, 81.71it/s] \n"]}]},{"cell_type":"markdown","source":["#### 텍스트 정규화"],"metadata":{"id":"OhZ2OdR7-iXV"}},{"cell_type":"code","source":["import re\n","from tqdm import tqdm\n","\n","def text_normalization(text):\n","    # 소문자 변환\n","    text = text.lower()\n","\n","    # 숫자 제거\n","    text = re.sub(r'\\d+', '', text)\n","\n","    # 특수문자 제거\n","    # text = re.sub(r'[^\\w\\s]', '', text)\n","\n","    return text\n","\n","tqdm.pandas()\n","train_data['content'] = train_data['content'].progress_apply(text_normalization)\n","test_data['content'] = test_data['content'].progress_apply(text_normalization)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Up9ltRfc-Syf","executionInfo":{"status":"ok","timestamp":1706766804068,"user_tz":-540,"elapsed":1552,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"cebde48f-9658-4feb-a060-a3a4b66f6bb2"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 45999/45999 [00:00<00:00, 51501.83it/s]\n","100%|██████████| 390/390 [00:00<00:00, 84235.98it/s]\n"]}]},{"cell_type":"markdown","source":["#### 반복 표현 제거(ex. ㅋㅋㅋㅋㅋㅋ,ㅎㅎㅎㅎㅎ)"],"metadata":{"id":"JHhzv9njGdxZ"}},{"cell_type":"code","source":["def replace_repeated_chars(text):\n","    # 두 번 이상 반복되는 글자(예: ㅋㅋㅋ, ㅎㅎㅎ)를 찾아 해당 글자의 두 번 반복으로 치환\n","    pattern = re.compile(r'(.)\\1{1,}', re.DOTALL)\n","\n","    # 정규식에 맞게 두 번 이상 반복되는 글자를 찾아 치환\n","    text = pattern.sub(r'\\1\\1', text)\n","\n","    return text\n","\n","# 'content' 열에 있는 각 텍스트에 대해 두 번 이상 반복되는 글자를 찾아 치환\n","tqdm.pandas()\n","train_data['content'] = train_data['content'].progress_apply(replace_repeated_chars)\n","test_data['content'] = test_data['content'].progress_apply(replace_repeated_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbruXSu7-vZ9","executionInfo":{"status":"ok","timestamp":1706766808514,"user_tz":-540,"elapsed":771,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"aba271d3-39df-4ef7-eed5-716f7a6f404f"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 45999/45999 [00:00<00:00, 81295.18it/s]\n","100%|██████████| 390/390 [00:00<00:00, 36051.81it/s]\n"]}]},{"cell_type":"code","source":["df_length = train_data['content'].astype(str).apply(len)\n","print('글 길이 최댓값: {}'.format(np.max(df_length)))\n","print('글 길이 최솟값: {}'.format(np.min(df_length)))\n","print('글 길이 평균값: {:.2f}'.format(np.mean(df_length)))\n","print('글 길이 중간값: {}'.format(np.median(df_length)))\n","print('글 길이 제1사분위: {}'.format(np.percentile(df_length,25)))\n","print('글 길이 제3사분위: {}'.format(np.percentile(df_length,75)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMlXsEwN-vXB","executionInfo":{"status":"ok","timestamp":1706766809300,"user_tz":-540,"elapsed":317,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"9feda2eb-c4c9-4c3d-ead6-8ea90095613f"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["글 길이 최댓값: 133\n","글 길이 최솟값: 1\n","글 길이 평균값: 30.01\n","글 길이 중간값: 29.0\n","글 길이 제1사분위: 19.0\n","글 길이 제3사분위: 39.0\n"]}]},{"cell_type":"code","source":["train_data = train_data[train_data['content'].str.len() > 5]\n","train_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X9_IrOpXr6xx","executionInfo":{"status":"ok","timestamp":1706766810335,"user_tz":-540,"elapsed":4,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"b0a3a03e-76e8-4917-a672-aede6fdf9d76"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(45853, 2)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["train_data.drop_duplicates(subset=['content'], inplace=True, ignore_index=True) # 중복 제거"],"metadata":{"id":"MzV8SV35q1sn","executionInfo":{"status":"ok","timestamp":1706766812017,"user_tz":-540,"elapsed":602,"user":{"displayName":"좌대현","userId":"14506643217253030071"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["## 토큰화"],"metadata":{"id":"peahPAinqOyD"}},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":1242,"status":"ok","timestamp":1706766814725,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"Nx_D1rlXfcB6"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', pad_token='<pad>')"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1706766814725,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"kHO4iiqQhP6D","outputId":"9ebd3080-d57f-4eee-81f6-38f0c4c7ec13"},"outputs":[{"output_type":"stream","name":"stdout","text":["['▁전', '율을', '▁일으키는', '▁영화', '.', '▁다시', '▁보고', '싶', '은', '▁영화']\n"]}],"source":["print(tokenizer.tokenize(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1706766815153,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"PTL9qUrvhRHz","outputId":"f445cd7a-fcc5-40a8-bfb1-b23b3d53326f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[9034, 13555, 16447, 10584, 389, 9427, 10056, 7898, 8135, 10584]\n"]}],"source":["print(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706766816086,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"-EM6Nw-LhUqq","outputId":"dfabd5e4-d893-4dfd-abe2-e6d284e70ebb"},"outputs":[{"output_type":"stream","name":"stdout","text":["<pad>\n"]}],"source":["print(tokenizer.decode(3))"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706766816396,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"VhPmUfylhVRy"},"outputs":[],"source":["max_seq_len = 128"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706766816751,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"GDnicNWphV-y","outputId":"7a822e79-7d81-440a-eb54-b0f8d6956b8d"},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["[9034, 13555, 16447, 10584, 389, 9427, 10056, 7898, 8135, 10584, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","길이 : 128\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["encoded_result = tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\", max_length=max_seq_len, pad_to_max_length=True)\n","print(encoded_result)\n","print('길이 :', len(encoded_result))"]},{"cell_type":"code","source":["answer = '안녕하세요 반가워요'\n","\n","# BOS와 EOS 토큰을 추가하여 리스트로 만듭니다.\n","answers = [tokenizer.bos_token] + [answer] + [tokenizer.eos_token]\n","\n","# 리스트를 문자열로 변환합니다.\n","answers_str = ' '.join(answers)\n","\n","# 토크나이저를 사용하여 패딩과 트러케이션을 적용합니다.\n","encoded_inputs = tokenizer(answers_str, return_tensors=\"pt\", max_length=256, padding=True, truncation=True)\n","\n","print(encoded_inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obT9b4bb6Gzf","executionInfo":{"status":"ok","timestamp":1706766817056,"user_tz":-540,"elapsed":3,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"ec47fa9d-49b7-489e-d93c-ef44fc31241f"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[    1, 25906,  8702,  7801,  8084, 36230,  8102,  8084,   739,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"]}]},{"cell_type":"markdown","source":["### 토큰화"],"metadata":{"id":"GQdYjCaJKjni"}},{"cell_type":"code","execution_count":65,"metadata":{"executionInfo":{"elapsed":314,"status":"ok","timestamp":1706766818613,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"qk8DJZ_khYgK"},"outputs":[],"source":["def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n","\n","    input_ids, data_labels = [], []\n","\n","    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n","\n","        bos_token = [tokenizer.bos_token]\n","        eos_token = [tokenizer.eos_token]\n","        tokens = bos_token + tokenizer.tokenize(example) + eos_token   # 토큰으로 나누고 bos, eos 토큰을 앞뒤로 붙여줌\n","        input_id = tokenizer.convert_tokens_to_ids(tokens)   # 토큰을 인덱스로 변경\n","        input_id = pad_sequences([input_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]    # 패딩\n","\n","        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n","        input_ids.append(input_id)\n","        data_labels.append(label)\n","\n","    input_ids = np.array(input_ids, dtype=int)\n","    data_labels = np.asarray(data_labels, dtype=np.int32)\n","\n","    return input_ids, data_labels"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14321,"status":"ok","timestamp":1706766833279,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"2q81CbrDhZYi","outputId":"49eb8baf-02ef-48f0-b28e-f8d307ae5b10"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 45710/45710 [00:14<00:00, 3257.02it/s]\n"]}],"source":["train_X, train_y = convert_examples_to_features(train_data['content'], train_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1706766833666,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"A0LLv-CchaTS","outputId":"917bc1bf-8247-4373-c011-1e5a65f329c7"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 390/390 [00:00<00:00, 3111.10it/s]\n"]}],"source":["test_X, test_y = convert_examples_to_features(test_data['content'], test_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":536,"status":"ok","timestamp":1706766895324,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"X1NT5huFhbDy","outputId":"d7d528e9-0988-434d-aba9-fa8749c7a368"},"outputs":[{"output_type":"stream","name":"stdout","text":["단어에 대한 정수 인코딩 : [    1 11275  8270 10607  9063 10056  9050  8185  7957 22990 36510     1\n","     3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     3]\n","각 인코딩의 길이 : 128\n","정수 인코딩 복원 : </s> 옆집 아이 나 보고 아저씨 래.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","레이블 : 1\n"]}],"source":["# 최대 길이: 128\n","input_id = train_X[0]\n","label = train_y[0]\n","\n","print('단어에 대한 정수 인코딩 :',input_id)\n","print('각 인코딩의 길이 :', len(input_id))\n","print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n","print('레이블 :',label)"]},{"cell_type":"markdown","source":["## 학습"],"metadata":{"id":"t25CCM2JstWb"}},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2781,"status":"ok","timestamp":1706766899456,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"dp6ZAIpYevaC","outputId":"862b0ee0-1698-477a-f866-769f23250ab9"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2Model: ['transformer.h.10.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'lm_head.weight']\n","- This IS expected if you are initializing TFGPT2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFGPT2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFGPT2Model were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"]}],"source":["model = TFGPT2Model.from_pretrained('skt/kogpt2-base-v2', from_pt=True)"]},{"cell_type":"code","execution_count":70,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706766899456,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"K-_jc-ft8tUp"},"outputs":[],"source":["max_seq_len = 128"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":3843,"status":"ok","timestamp":1706766904176,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"p_lt6RAclTjU"},"outputs":[],"source":["input_ids_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n","outputs = model([input_ids_layer])"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706766904176,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"W68IEgzUlay_","outputId":"0f8840ae-a46a-4cb9-e04d-0cf630e57deb"},"outputs":[{"output_type":"stream","name":"stdout","text":["TFBaseModelOutputWithPastAndCrossAttentions(last_hidden_state=<KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'tfgpt2_model_2')>, past_key_values=(<KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_2')>), hidden_states=None, attentions=None, cross_attentions=None)\n"]}],"source":["print(outputs)"]},{"cell_type":"code","execution_count":73,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706766904608,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"21Xtk14tTECJ"},"outputs":[],"source":["class TFGPT2ForSequenceClassification(tf.keras.Model):\n","    def __init__(self, model_name):\n","        super(TFGPT2ForSequenceClassification, self).__init__()\n","        self.gpt = TFGPT2Model.from_pretrained(model_name, from_pt=True)\n","        self.dropout = tf.keras.layers.Dropout(0.2)\n","        self.classifier = tf.keras.layers.Dense(1,\n","                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n","                                                activation='sigmoid',\n","                                                name='classifier')\n","\n","    def call(self, inputs):\n","        outputs = self.gpt(input_ids=inputs)\n","        cls_token = outputs[0][:, -1]\n","        cls_token = self.dropout(cls_token)\n","        prediction = self.classifier(cls_token)\n","\n","        return prediction"]},{"cell_type":"markdown","metadata":{"id":"W0ZgufoPH5-b"},"source":["TPU 사용법 : https://wikidocs.net/119990"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"9_6nzezphcoy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706767096138,"user_tz":-540,"elapsed":12052,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"9f20ea8e-fdc5-4474-c246-bbc1924a399a"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:TPU system grpc://10.69.51.234:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.tpu.topology.Topology at 0x7bca5d787520>"]},"metadata":{},"execution_count":74}],"source":["# TPU 작동을 위한 코드\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"M-xMJuCjUxIn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706767096139,"user_tz":-540,"elapsed":25,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"ad39a39a-8b70-40e9-8837-d48d508d5439"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"]}],"source":["strategy = tf.distribute.experimental.TPUStrategy(resolver)"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"wz2VsrZnUeJf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706767111817,"user_tz":-540,"elapsed":15700,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"9254ce76-57a6-4b2f-d754-06e4434bf350"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2Model: ['transformer.h.10.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'lm_head.weight']\n","- This IS expected if you are initializing TFGPT2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFGPT2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFGPT2Model were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"]}],"source":["with strategy.scope():\n","  model = TFGPT2ForSequenceClassification(\"skt/kogpt2-base-v2\")\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","  loss = tf.keras.losses.BinaryCrossentropy()\n","  model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334908,"status":"ok","timestamp":1706767446705,"user":{"displayName":"좌대현","userId":"14506643217253030071"},"user_tz":-540},"id":"DQEGFSnbU8U1","outputId":"63b99d75-2df9-4085-a090-30b87a1eab8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1143/1143 [==============================] - 215s 124ms/step - loss: 0.3429 - accuracy: 0.8610 - val_loss: 0.3161 - val_accuracy: 0.8845\n","Epoch 2/2\n","1143/1143 [==============================] - 96s 84ms/step - loss: 0.2160 - accuracy: 0.9192 - val_loss: 0.1290 - val_accuracy: 0.9552\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7bc8d76595a0>"]},"metadata":{},"execution_count":77}],"source":["model.fit(train_X, train_y, epochs=2, batch_size=32, validation_split=0.2)"]},{"cell_type":"markdown","source":["## 평가, 예측"],"metadata":{"id":"YyUzE0Ugu1zd"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","# 모델 예측\n","predictions = model.predict(test_X)\n","\n","# 이진 분류에서는 predictions를 0 또는 1로 변환해주어야 합니다.\n","binary_predictions = (predictions > 0.5).astype(int)\n","\n","# 정밀도, 재현율, F1 스코어 계산\n","accuracy = accuracy_score(test_y, binary_predictions)\n","precision = precision_score(test_y, binary_predictions)\n","recall = recall_score(test_y, binary_predictions)\n","f1 = f1_score(test_y, binary_predictions)\n","\n","print(\"accuracy: {:.4f}\".format(accuracy))\n","print(\"precision: {:.4f}\".format(precision))\n","print(\"recall: {:.4f}\".format(recall))\n","print(\"F1 Score: {:.4f}\".format(f1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNmmXg9Sudyl","executionInfo":{"status":"ok","timestamp":1706767509658,"user_tz":-540,"elapsed":11791,"user":{"displayName":"좌대현","userId":"14506643217253030071"}},"outputId":"2b43a543-85c7-4aa6-90a9-2248b891bfbd"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["13/13 [==============================] - 11s 553ms/step\n","accuracy: 0.7769\n","precision: 0.9365\n","recall: 0.5990\n","F1 Score: 0.7307\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0smzz7Jh0Mw"},"outputs":[],"source":["def sentiment_predict(new_sentence):\n","\n","  bos_token = [tokenizer.bos_token]\n","  eos_token = [tokenizer.eos_token]\n","  tokens = bos_token + tokenizer.tokenize(new_sentence) + eos_token\n","  input_id = tokenizer.convert_tokens_to_ids(tokens)\n","  input_id = pad_sequences([input_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]\n","  input_id = np.array([input_id])\n","  score = model.predict(input_id)[0][0]\n","\n","  if(score > 0.5):\n","    print(\"{:.2f}% 확률로 우울글입니다.\\n\".format(score * 100))\n","  else:\n","    print(\"{:.2f}% 확률로 우울글이 아닙니다.\\n\".format((1 - score) * 100))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRA5_U3nkjKH","outputId":"8a98193a-a6a5-4255-9058-783d6486062e","executionInfo":{"status":"ok","timestamp":1706590877679,"user_tz":-540,"elapsed":7532,"user":{"displayName":"좌대현","userId":"14506643217253030071"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 7s 7s/step\n","93.12% 확률로 우울글이 아닙니다.\n","\n"]}],"source":["sentiment_predict('보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqpAeDCGkkXj","outputId":"123ab9da-0675-45bf-c79c-4d5c26af9ecb","executionInfo":{"status":"ok","timestamp":1706590881787,"user_tz":-540,"elapsed":1223,"user":{"displayName":"좌대현","userId":"14506643217253030071"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 721ms/step\n","79.70% 확률로 우울글입니다.\n","\n"]}],"source":["sentiment_predict(\"스토리는 확실히 실망이였지만 배우들 연기력이 대박이였다 특히 이제훈 연기 정말 ... 이 배우들로 이렇게밖에 만들지 못한 영화는 아쉽지만 배우들 연기력과 사운드는 정말 빛났던 영화. 기대하고 극장에서 보면 많이 실망했겠지만 평점보고 기대없이 집에서 편하게 보면 괜찮아요. 이제훈님 연기력은 최고인 것 같습니다\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OxifMVDekyov","outputId":"c8bd3af6-ae1b-4023-d3d7-98d4f0bbe4f2","executionInfo":{"status":"ok","timestamp":1706590886282,"user_tz":-540,"elapsed":1031,"user":{"displayName":"좌대현","userId":"14506643217253030071"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 660ms/step\n","80.35% 확률로 우울글입니다.\n","\n"]}],"source":["sentiment_predict(\"남친이 이 영화를 보고 헤어지자고한 영화. 자유롭게 살고 싶다고 한다. 내가 무슨 나비를 잡은 덫마냥 나에겐 다시 보고싶지 않은 영화.\")"]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}